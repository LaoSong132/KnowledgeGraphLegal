{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flair Model Relation Extraction Training Code on Sample Corpus RE_ENGLISH_CONLL04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import RelationExtractor\n",
    "from flair.datasets import RE_ENGLISH_DRUGPROT\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.embeddings import WordEmbeddings\n",
    "from torch.optim.adam import Adam\n",
    "from flair.datasets import RE_ENGLISH_CONLL04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 10\n",
    "lr = 0.01\n",
    "model_path = \"models/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 21:58:28,840 Reading data from /home/hdu5/.flair/datasets/re_english_conll04\n",
      "2021-12-03 21:58:28,840 Train: /home/hdu5/.flair/datasets/re_english_conll04/conll04-train.conllu\n",
      "2021-12-03 21:58:28,841 Dev: /home/hdu5/.flair/datasets/re_english_conll04/conll04-dev.conllu\n",
      "2021-12-03 21:58:28,841 Test: /home/hdu5/.flair/datasets/re_english_conll04/conll04-test.conllu\n",
      "2021-12-03 21:58:29,485 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 910/910 [00:00<00:00, 19257.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 21:58:29,534 Corpus contains the labels: ner (#26804), sentence_id (#910), relation (#910), entity (#910)\n",
      "2021-12-03 21:58:29,534 Created (for label 'relation') Dictionary with 6 tags: <unk>, Located_In, Work_For, Live_In, OrgBased_In, Kill\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'span_label_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23061/100623815.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"glove\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#classifier = RelationExtractor(embeddings, label_dictionary=label_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m classifier = RelationExtractor(embeddings,\n\u001b[0m\u001b[1;32m      6\u001b[0m                                 \u001b[0mlabel_dictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                 \u001b[0mlabel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/flair/models/relation_extractor_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, embeddings, label_type, entity_label_type, train_on_gold_pairs_only, entity_pair_filters, pooling_operation, dropout_value, locked_dropout_value, word_dropout_value, non_linear_decoder, **classifierargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0munspecified\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mto\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRelationExtractor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mclassifierargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# set embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'span_label_type'"
     ]
    }
   ],
   "source": [
    "corpus = RE_ENGLISH_CONLL04()\n",
    "label_dict = corpus.make_label_dictionary(\"relation\")\n",
    "embeddings = WordEmbeddings(\"glove\")\n",
    "#classifier = RelationExtractor(embeddings, label_dictionary=label_dict)\n",
    "classifier = RelationExtractor(embeddings,\n",
    "                                label_dictionary=label_dict,\n",
    "                                label_type=\"relation\",\n",
    "                                span_label_type=\"ner\",\n",
    "                                entity_label_type=\"relation\",\n",
    "                                )\n",
    "trainer = ModelTrainer(classifier, corpus, optimizer=Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "RelationExtractor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-11 01:48:28,552 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:28,554 Model: \"RelationExtractor(\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (token_embeddings): WordEmbeddings('glove')\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (decoder): Linear(in_features=400, out_features=6, bias=True)\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-11-11 01:48:28,555 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:28,556 Corpus: \"Corpus: 910 train + 243 dev + 288 test sentences\"\n",
      "2021-11-11 01:48:28,557 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:28,558 Parameters:\n",
      "2021-11-11 01:48:28,559  - learning_rate: \"0.01\"\n",
      "2021-11-11 01:48:28,560  - mini_batch_size: \"16\"\n",
      "2021-11-11 01:48:28,561  - patience: \"3\"\n",
      "2021-11-11 01:48:28,563  - anneal_factor: \"0.5\"\n",
      "2021-11-11 01:48:28,564  - max_epochs: \"10\"\n",
      "2021-11-11 01:48:28,565  - shuffle: \"True\"\n",
      "2021-11-11 01:48:28,566  - train_with_dev: \"False\"\n",
      "2021-11-11 01:48:28,567  - batch_growth_annealing: \"False\"\n",
      "2021-11-11 01:48:28,569 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:28,569 Model training base path: \"models\"\n",
      "2021-11-11 01:48:28,570 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:28,570 Device: cpu\n",
      "2021-11-11 01:48:28,571 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:28,572 Embeddings storage mode: cpu\n",
      "2021-11-11 01:48:28,596 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:28,741 epoch 1 - iter 5/57 - loss 0.01562766 - samples/sec: 557.74 - lr: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\envs\\gdm36\\lib\\site-packages\\flair\\trainers\\trainer.py:77: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  \"There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-11 01:48:28,833 epoch 1 - iter 10/57 - loss 0.01445957 - samples/sec: 889.18 - lr: 0.010000\n",
      "2021-11-11 01:48:28,915 epoch 1 - iter 15/57 - loss 0.01413398 - samples/sec: 994.75 - lr: 0.010000\n",
      "2021-11-11 01:48:28,974 epoch 1 - iter 20/57 - loss 0.01359350 - samples/sec: 1401.94 - lr: 0.010000\n",
      "2021-11-11 01:48:29,057 epoch 1 - iter 25/57 - loss 0.01340373 - samples/sec: 1062.18 - lr: 0.010000\n",
      "2021-11-11 01:48:29,139 epoch 1 - iter 30/57 - loss 0.01317362 - samples/sec: 1034.67 - lr: 0.010000\n",
      "2021-11-11 01:48:29,215 epoch 1 - iter 35/57 - loss 0.01227360 - samples/sec: 1059.20 - lr: 0.010000\n",
      "2021-11-11 01:48:29,289 epoch 1 - iter 40/57 - loss 0.01108719 - samples/sec: 1137.25 - lr: 0.010000\n",
      "2021-11-11 01:48:29,358 epoch 1 - iter 45/57 - loss 0.01153639 - samples/sec: 1238.81 - lr: 0.010000\n",
      "2021-11-11 01:48:29,438 epoch 1 - iter 50/57 - loss 0.01145550 - samples/sec: 1080.70 - lr: 0.010000\n",
      "2021-11-11 01:48:29,500 epoch 1 - iter 55/57 - loss 0.01201507 - samples/sec: 1311.57 - lr: 0.010000\n",
      "2021-11-11 01:48:29,546 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:29,551 EPOCH 1 done: loss 0.0118 - lr 0.0100000\n",
      "2021-11-11 01:48:30,025 DEV : loss 0.010583966039121151 - f1-score (micro avg)  0.3724\n",
      "2021-11-11 01:48:30,609 TEST : loss 0.009358759969472885 - f1-score (micro avg)  0.3362\n",
      "2021-11-11 01:48:30,636 BAD EPOCHS (no improvement): 0\n",
      "2021-11-11 01:48:30,638 saving best model\n",
      "2021-11-11 01:48:34,077 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:34,187 epoch 2 - iter 5/57 - loss 0.00778684 - samples/sec: 1070.50 - lr: 0.010000\n",
      "2021-11-11 01:48:34,245 epoch 2 - iter 10/57 - loss 0.00821617 - samples/sec: 1432.86 - lr: 0.010000\n",
      "2021-11-11 01:48:34,307 epoch 2 - iter 15/57 - loss 0.00935318 - samples/sec: 1340.13 - lr: 0.010000\n",
      "2021-11-11 01:48:34,365 epoch 2 - iter 20/57 - loss 0.00895518 - samples/sec: 1561.69 - lr: 0.010000\n",
      "2021-11-11 01:48:34,451 epoch 2 - iter 25/57 - loss 0.00849221 - samples/sec: 948.41 - lr: 0.010000\n",
      "2021-11-11 01:48:34,547 epoch 2 - iter 30/57 - loss 0.00823752 - samples/sec: 875.61 - lr: 0.010000\n",
      "2021-11-11 01:48:34,614 epoch 2 - iter 35/57 - loss 0.00820585 - samples/sec: 1244.91 - lr: 0.010000\n",
      "2021-11-11 01:48:34,689 epoch 2 - iter 40/57 - loss 0.00779193 - samples/sec: 1114.24 - lr: 0.010000\n",
      "2021-11-11 01:48:34,748 epoch 2 - iter 45/57 - loss 0.00762022 - samples/sec: 1427.20 - lr: 0.010000\n",
      "2021-11-11 01:48:34,837 epoch 2 - iter 50/57 - loss 0.00746429 - samples/sec: 923.95 - lr: 0.010000\n",
      "2021-11-11 01:48:34,925 epoch 2 - iter 55/57 - loss 0.00751263 - samples/sec: 950.28 - lr: 0.010000\n",
      "2021-11-11 01:48:34,961 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:34,963 EPOCH 2 done: loss 0.0072 - lr 0.0100000\n",
      "2021-11-11 01:48:35,323 DEV : loss 0.008846312761306763 - f1-score (micro avg)  0.3745\n",
      "2021-11-11 01:48:35,828 TEST : loss 0.007249113172292709 - f1-score (micro avg)  0.4005\n",
      "2021-11-11 01:48:35,847 BAD EPOCHS (no improvement): 0\n",
      "2021-11-11 01:48:35,852 saving best model\n",
      "2021-11-11 01:48:38,803 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:38,874 epoch 3 - iter 5/57 - loss 0.00593488 - samples/sec: 1164.33 - lr: 0.010000\n",
      "2021-11-11 01:48:38,943 epoch 3 - iter 10/57 - loss 0.00539968 - samples/sec: 1227.54 - lr: 0.010000\n",
      "2021-11-11 01:48:38,999 epoch 3 - iter 15/57 - loss 0.00577791 - samples/sec: 1533.20 - lr: 0.010000\n",
      "2021-11-11 01:48:39,065 epoch 3 - iter 20/57 - loss 0.00517631 - samples/sec: 1568.78 - lr: 0.010000\n",
      "2021-11-11 01:48:39,131 epoch 3 - iter 25/57 - loss 0.00514567 - samples/sec: 1458.46 - lr: 0.010000\n",
      "2021-11-11 01:48:39,199 epoch 3 - iter 30/57 - loss 0.00526548 - samples/sec: 1291.00 - lr: 0.010000\n",
      "2021-11-11 01:48:39,249 epoch 3 - iter 35/57 - loss 0.00545445 - samples/sec: 1757.42 - lr: 0.010000\n",
      "2021-11-11 01:48:39,309 epoch 3 - iter 40/57 - loss 0.00548898 - samples/sec: 1493.45 - lr: 0.010000\n",
      "2021-11-11 01:48:39,363 epoch 3 - iter 45/57 - loss 0.00562867 - samples/sec: 1641.75 - lr: 0.010000\n",
      "2021-11-11 01:48:39,414 epoch 3 - iter 50/57 - loss 0.00580580 - samples/sec: 1616.22 - lr: 0.010000\n",
      "2021-11-11 01:48:39,466 epoch 3 - iter 55/57 - loss 0.00571095 - samples/sec: 1588.30 - lr: 0.010000\n",
      "2021-11-11 01:48:39,495 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:39,495 EPOCH 3 done: loss 0.0057 - lr 0.0100000\n",
      "2021-11-11 01:48:39,877 DEV : loss 0.008331571705639362 - f1-score (micro avg)  0.3931\n",
      "2021-11-11 01:48:40,310 TEST : loss 0.0069500901736319065 - f1-score (micro avg)  0.4172\n",
      "2021-11-11 01:48:40,341 BAD EPOCHS (no improvement): 0\n",
      "2021-11-11 01:48:40,348 saving best model\n",
      "2021-11-11 01:48:43,574 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:43,663 epoch 4 - iter 5/57 - loss 0.00517552 - samples/sec: 922.03 - lr: 0.010000\n",
      "2021-11-11 01:48:43,742 epoch 4 - iter 10/57 - loss 0.00546720 - samples/sec: 1036.53 - lr: 0.010000\n",
      "2021-11-11 01:48:43,807 epoch 4 - iter 15/57 - loss 0.00533282 - samples/sec: 1299.87 - lr: 0.010000\n",
      "2021-11-11 01:48:43,900 epoch 4 - iter 20/57 - loss 0.00515012 - samples/sec: 882.18 - lr: 0.010000\n",
      "2021-11-11 01:48:43,993 epoch 4 - iter 25/57 - loss 0.00522585 - samples/sec: 907.81 - lr: 0.010000\n",
      "2021-11-11 01:48:44,056 epoch 4 - iter 30/57 - loss 0.00517121 - samples/sec: 1297.40 - lr: 0.010000\n",
      "2021-11-11 01:48:44,136 epoch 4 - iter 35/57 - loss 0.00493223 - samples/sec: 1099.87 - lr: 0.010000\n",
      "2021-11-11 01:48:44,205 epoch 4 - iter 40/57 - loss 0.00505052 - samples/sec: 1199.59 - lr: 0.010000\n",
      "2021-11-11 01:48:44,267 epoch 4 - iter 45/57 - loss 0.00526622 - samples/sec: 1329.01 - lr: 0.010000\n",
      "2021-11-11 01:48:44,329 epoch 4 - iter 50/57 - loss 0.00548793 - samples/sec: 1335.05 - lr: 0.010000\n",
      "2021-11-11 01:48:44,419 epoch 4 - iter 55/57 - loss 0.00535136 - samples/sec: 902.38 - lr: 0.010000\n",
      "2021-11-11 01:48:44,441 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:44,442 EPOCH 4 done: loss 0.0054 - lr 0.0100000\n",
      "2021-11-11 01:48:44,919 DEV : loss 0.008675082586705685 - f1-score (micro avg)  0.4006\n",
      "2021-11-11 01:48:45,341 TEST : loss 0.007141821552067995 - f1-score (micro avg)  0.396\n",
      "2021-11-11 01:48:45,361 BAD EPOCHS (no improvement): 0\n",
      "2021-11-11 01:48:45,363 saving best model\n",
      "2021-11-11 01:48:48,425 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:48,506 epoch 5 - iter 5/57 - loss 0.00584615 - samples/sec: 1061.73 - lr: 0.010000\n",
      "2021-11-11 01:48:48,587 epoch 5 - iter 10/57 - loss 0.00506474 - samples/sec: 1022.13 - lr: 0.010000\n",
      "2021-11-11 01:48:48,692 epoch 5 - iter 15/57 - loss 0.00424319 - samples/sec: 786.40 - lr: 0.010000\n",
      "2021-11-11 01:48:48,752 epoch 5 - iter 20/57 - loss 0.00503861 - samples/sec: 1437.81 - lr: 0.010000\n",
      "2021-11-11 01:48:48,816 epoch 5 - iter 25/57 - loss 0.00489361 - samples/sec: 1259.80 - lr: 0.010000\n",
      "2021-11-11 01:48:48,875 epoch 5 - iter 30/57 - loss 0.00499751 - samples/sec: 1522.63 - lr: 0.010000\n",
      "2021-11-11 01:48:48,923 epoch 5 - iter 35/57 - loss 0.00519763 - samples/sec: 1703.22 - lr: 0.010000\n",
      "2021-11-11 01:48:48,965 epoch 5 - iter 40/57 - loss 0.00531704 - samples/sec: 1965.41 - lr: 0.010000\n",
      "2021-11-11 01:48:49,022 epoch 5 - iter 45/57 - loss 0.00523514 - samples/sec: 1569.29 - lr: 0.010000\n",
      "2021-11-11 01:48:49,104 epoch 5 - iter 50/57 - loss 0.00525838 - samples/sec: 1014.09 - lr: 0.010000\n",
      "2021-11-11 01:48:49,179 epoch 5 - iter 55/57 - loss 0.00524362 - samples/sec: 1117.39 - lr: 0.010000\n",
      "2021-11-11 01:48:49,206 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:49,210 EPOCH 5 done: loss 0.0053 - lr 0.0100000\n",
      "2021-11-11 01:48:49,582 DEV : loss 0.008122303523123264 - f1-score (micro avg)  0.4049\n",
      "2021-11-11 01:48:50,081 TEST : loss 0.006624876521527767 - f1-score (micro avg)  0.3853\n",
      "2021-11-11 01:48:50,108 BAD EPOCHS (no improvement): 0\n",
      "2021-11-11 01:48:50,110 saving best model\n",
      "2021-11-11 01:48:53,376 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:53,440 epoch 6 - iter 5/57 - loss 0.00580151 - samples/sec: 1350.02 - lr: 0.010000\n",
      "2021-11-11 01:48:53,491 epoch 6 - iter 10/57 - loss 0.00467022 - samples/sec: 1610.06 - lr: 0.010000\n",
      "2021-11-11 01:48:53,549 epoch 6 - iter 15/57 - loss 0.00496779 - samples/sec: 1535.20 - lr: 0.010000\n",
      "2021-11-11 01:48:53,623 epoch 6 - iter 20/57 - loss 0.00504787 - samples/sec: 1161.76 - lr: 0.010000\n",
      "2021-11-11 01:48:53,685 epoch 6 - iter 25/57 - loss 0.00517281 - samples/sec: 1392.92 - lr: 0.010000\n",
      "2021-11-11 01:48:53,732 epoch 6 - iter 30/57 - loss 0.00525493 - samples/sec: 1829.50 - lr: 0.010000\n",
      "2021-11-11 01:48:53,800 epoch 6 - iter 35/57 - loss 0.00519612 - samples/sec: 1285.25 - lr: 0.010000\n",
      "2021-11-11 01:48:53,858 epoch 6 - iter 40/57 - loss 0.00529758 - samples/sec: 1431.38 - lr: 0.010000\n",
      "2021-11-11 01:48:53,916 epoch 6 - iter 45/57 - loss 0.00531602 - samples/sec: 1513.50 - lr: 0.010000\n",
      "2021-11-11 01:48:53,974 epoch 6 - iter 50/57 - loss 0.00517187 - samples/sec: 1504.31 - lr: 0.010000\n",
      "2021-11-11 01:48:54,042 epoch 6 - iter 55/57 - loss 0.00488596 - samples/sec: 1336.59 - lr: 0.010000\n",
      "2021-11-11 01:48:54,061 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:54,065 EPOCH 6 done: loss 0.0049 - lr 0.0100000\n",
      "2021-11-11 01:48:54,380 DEV : loss 0.008264914155006409 - f1-score (micro avg)  0.361\n",
      "2021-11-11 01:48:54,757 TEST : loss 0.006762618664652109 - f1-score (micro avg)  0.3429\n",
      "2021-11-11 01:48:54,788 BAD EPOCHS (no improvement): 1\n",
      "2021-11-11 01:48:54,790 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:54,839 epoch 7 - iter 5/57 - loss 0.00654668 - samples/sec: 1704.78 - lr: 0.010000\n",
      "2021-11-11 01:48:54,895 epoch 7 - iter 10/57 - loss 0.00585034 - samples/sec: 1589.47 - lr: 0.010000\n",
      "2021-11-11 01:48:54,938 epoch 7 - iter 15/57 - loss 0.00627903 - samples/sec: 1894.96 - lr: 0.010000\n",
      "2021-11-11 01:48:54,987 epoch 7 - iter 20/57 - loss 0.00564334 - samples/sec: 1645.75 - lr: 0.010000\n",
      "2021-11-11 01:48:55,045 epoch 7 - iter 25/57 - loss 0.00509836 - samples/sec: 1594.61 - lr: 0.010000\n",
      "2021-11-11 01:48:55,120 epoch 7 - iter 30/57 - loss 0.00453658 - samples/sec: 1126.26 - lr: 0.010000\n",
      "2021-11-11 01:48:55,188 epoch 7 - iter 35/57 - loss 0.00459654 - samples/sec: 1234.44 - lr: 0.010000\n",
      "2021-11-11 01:48:55,258 epoch 7 - iter 40/57 - loss 0.00483207 - samples/sec: 1157.60 - lr: 0.010000\n",
      "2021-11-11 01:48:55,328 epoch 7 - iter 45/57 - loss 0.00494371 - samples/sec: 1150.67 - lr: 0.010000\n",
      "2021-11-11 01:48:55,390 epoch 7 - iter 50/57 - loss 0.00486178 - samples/sec: 1406.16 - lr: 0.010000\n",
      "2021-11-11 01:48:55,452 epoch 7 - iter 55/57 - loss 0.00479942 - samples/sec: 1360.99 - lr: 0.010000\n",
      "2021-11-11 01:48:55,476 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:55,477 EPOCH 7 done: loss 0.0048 - lr 0.0100000\n",
      "2021-11-11 01:48:55,837 DEV : loss 0.0077658421359956264 - f1-score (micro avg)  0.4461\n",
      "2021-11-11 01:48:56,385 TEST : loss 0.006580144166946411 - f1-score (micro avg)  0.4199\n",
      "2021-11-11 01:48:56,415 BAD EPOCHS (no improvement): 0\n",
      "2021-11-11 01:48:56,416 saving best model\n",
      "2021-11-11 01:48:59,394 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:48:59,482 epoch 8 - iter 5/57 - loss 0.00401508 - samples/sec: 1024.79 - lr: 0.010000\n",
      "2021-11-11 01:48:59,530 epoch 8 - iter 10/57 - loss 0.00379849 - samples/sec: 1694.42 - lr: 0.010000\n",
      "2021-11-11 01:48:59,599 epoch 8 - iter 15/57 - loss 0.00405803 - samples/sec: 1264.05 - lr: 0.010000\n",
      "2021-11-11 01:48:59,656 epoch 8 - iter 20/57 - loss 0.00393570 - samples/sec: 1437.81 - lr: 0.010000\n",
      "2021-11-11 01:48:59,713 epoch 8 - iter 25/57 - loss 0.00420040 - samples/sec: 1569.36 - lr: 0.010000\n",
      "2021-11-11 01:48:59,782 epoch 8 - iter 30/57 - loss 0.00434272 - samples/sec: 1675.76 - lr: 0.010000\n",
      "2021-11-11 01:48:59,840 epoch 8 - iter 35/57 - loss 0.00439766 - samples/sec: 1399.73 - lr: 0.010000\n",
      "2021-11-11 01:48:59,906 epoch 8 - iter 40/57 - loss 0.00447618 - samples/sec: 1391.79 - lr: 0.010000\n",
      "2021-11-11 01:48:59,955 epoch 8 - iter 45/57 - loss 0.00444720 - samples/sec: 1806.58 - lr: 0.010000\n",
      "2021-11-11 01:49:00,013 epoch 8 - iter 50/57 - loss 0.00438206 - samples/sec: 1638.73 - lr: 0.010000\n",
      "2021-11-11 01:49:00,096 epoch 8 - iter 55/57 - loss 0.00438799 - samples/sec: 1055.59 - lr: 0.010000\n",
      "2021-11-11 01:49:00,120 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:49:00,123 EPOCH 8 done: loss 0.0045 - lr 0.0100000\n",
      "2021-11-11 01:49:00,409 DEV : loss 0.0078763822093606 - f1-score (micro avg)  0.4044\n",
      "2021-11-11 01:49:00,784 TEST : loss 0.006463869474828243 - f1-score (micro avg)  0.4356\n",
      "2021-11-11 01:49:00,797 BAD EPOCHS (no improvement): 1\n",
      "2021-11-11 01:49:00,813 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:49:00,875 epoch 9 - iter 5/57 - loss 0.00339646 - samples/sec: 1334.40 - lr: 0.010000\n",
      "2021-11-11 01:49:00,916 epoch 9 - iter 10/57 - loss 0.00415685 - samples/sec: 2027.09 - lr: 0.010000\n",
      "2021-11-11 01:49:00,974 epoch 9 - iter 15/57 - loss 0.00401957 - samples/sec: 1624.05 - lr: 0.010000\n",
      "2021-11-11 01:49:01,034 epoch 9 - iter 20/57 - loss 0.00388251 - samples/sec: 1496.22 - lr: 0.010000\n",
      "2021-11-11 01:49:01,108 epoch 9 - iter 25/57 - loss 0.00390318 - samples/sec: 1159.47 - lr: 0.010000\n",
      "2021-11-11 01:49:01,175 epoch 9 - iter 30/57 - loss 0.00417646 - samples/sec: 1236.17 - lr: 0.010000\n",
      "2021-11-11 01:49:01,234 epoch 9 - iter 35/57 - loss 0.00407618 - samples/sec: 1475.30 - lr: 0.010000\n",
      "2021-11-11 01:49:01,300 epoch 9 - iter 40/57 - loss 0.00411352 - samples/sec: 1589.26 - lr: 0.010000\n",
      "2021-11-11 01:49:01,357 epoch 9 - iter 45/57 - loss 0.00422815 - samples/sec: 1620.59 - lr: 0.010000\n",
      "2021-11-11 01:49:01,427 epoch 9 - iter 50/57 - loss 0.00433184 - samples/sec: 1285.45 - lr: 0.010000\n",
      "2021-11-11 01:49:01,501 epoch 9 - iter 55/57 - loss 0.00430831 - samples/sec: 1156.66 - lr: 0.010000\n",
      "2021-11-11 01:49:01,533 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:49:01,535 EPOCH 9 done: loss 0.0043 - lr 0.0100000\n",
      "2021-11-11 01:49:01,839 DEV : loss 0.007878839038312435 - f1-score (micro avg)  0.4318\n",
      "2021-11-11 01:49:02,218 TEST : loss 0.006809770129621029 - f1-score (micro avg)  0.4089\n",
      "2021-11-11 01:49:02,242 BAD EPOCHS (no improvement): 2\n",
      "2021-11-11 01:49:02,254 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:49:02,307 epoch 10 - iter 5/57 - loss 0.00415321 - samples/sec: 1561.28 - lr: 0.010000\n",
      "2021-11-11 01:49:02,359 epoch 10 - iter 10/57 - loss 0.00481737 - samples/sec: 1730.06 - lr: 0.010000\n",
      "2021-11-11 01:49:02,409 epoch 10 - iter 15/57 - loss 0.00482019 - samples/sec: 1693.33 - lr: 0.010000\n",
      "2021-11-11 01:49:02,478 epoch 10 - iter 20/57 - loss 0.00481904 - samples/sec: 1296.11 - lr: 0.010000\n",
      "2021-11-11 01:49:02,540 epoch 10 - iter 25/57 - loss 0.00472780 - samples/sec: 1458.89 - lr: 0.010000\n",
      "2021-11-11 01:49:02,604 epoch 10 - iter 30/57 - loss 0.00468957 - samples/sec: 1463.17 - lr: 0.010000\n",
      "2021-11-11 01:49:02,673 epoch 10 - iter 35/57 - loss 0.00443818 - samples/sec: 1187.76 - lr: 0.010000\n",
      "2021-11-11 01:49:02,724 epoch 10 - iter 40/57 - loss 0.00456020 - samples/sec: 1706.27 - lr: 0.010000\n",
      "2021-11-11 01:49:02,789 epoch 10 - iter 45/57 - loss 0.00443270 - samples/sec: 1287.56 - lr: 0.010000\n",
      "2021-11-11 01:49:02,850 epoch 10 - iter 50/57 - loss 0.00434209 - samples/sec: 1435.98 - lr: 0.010000\n",
      "2021-11-11 01:49:02,906 epoch 10 - iter 55/57 - loss 0.00430362 - samples/sec: 1541.26 - lr: 0.010000\n",
      "2021-11-11 01:49:02,939 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:49:02,942 EPOCH 10 done: loss 0.0043 - lr 0.0100000\n",
      "2021-11-11 01:49:03,216 DEV : loss 0.007700772490352392 - f1-score (micro avg)  0.4626\n",
      "2021-11-11 01:49:03,617 TEST : loss 0.006795569788664579 - f1-score (micro avg)  0.4368\n",
      "2021-11-11 01:49:03,626 BAD EPOCHS (no improvement): 0\n",
      "2021-11-11 01:49:03,643 saving best model\n",
      "2021-11-11 01:49:09,535 ----------------------------------------------------------------------------------------------------\n",
      "2021-11-11 01:49:09,551 loading file models\\best-model.pt\n",
      "2021-11-11 01:49:13,274 0.4241\t0.4502\t0.4368\t0.2849\n",
      "2021-11-11 01:49:13,276 \n",
      "Results:\n",
      "- F-score (micro) 0.4368\n",
      "- F-score (macro) 0.4471\n",
      "- Accuracy 0.2849\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Live_In     0.4109    0.5300    0.4629       100\n",
      " OrgBased_In     0.3861    0.3714    0.3786       105\n",
      "    Work_For     0.4217    0.4605    0.4403        76\n",
      "  Located_In     0.3621    0.2234    0.2763        94\n",
      "        Kill     0.5455    0.8936    0.6774        47\n",
      "\n",
      "   micro avg     0.4241    0.4502    0.4368       422\n",
      "   macro avg     0.4252    0.4958    0.4471       422\n",
      "weighted avg     0.4108    0.4502    0.4202       422\n",
      " samples avg     0.2849    0.2849    0.2849       422\n",
      "\n",
      "2021-11-11 01:49:13,278 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.4367816091954022,\n",
       " 'dev_score_history': [0.37235228539576365,\n",
       "  0.3744911804613297,\n",
       "  0.3931133428981348,\n",
       "  0.4006211180124224,\n",
       "  0.4049459041731067,\n",
       "  0.36097560975609755,\n",
       "  0.4460856720827179,\n",
       "  0.4044233807266983,\n",
       "  0.4318181818181818,\n",
       "  0.46264367816091956],\n",
       " 'train_loss_history': [0.011829139326599616,\n",
       "  0.007156941165671379,\n",
       "  0.005725879846653121,\n",
       "  0.005425853291556577,\n",
       "  0.005261653112880524,\n",
       "  0.004947415481903214,\n",
       "  0.004759331107513322,\n",
       "  0.004495106781847944,\n",
       "  0.004340640383450055,\n",
       "  0.0042877280614474446],\n",
       " 'dev_loss_history': [tensor(0.0106),\n",
       "  tensor(0.0088),\n",
       "  tensor(0.0083),\n",
       "  tensor(0.0087),\n",
       "  tensor(0.0081),\n",
       "  tensor(0.0083),\n",
       "  tensor(0.0078),\n",
       "  tensor(0.0079),\n",
       "  tensor(0.0079),\n",
       "  tensor(0.0077)]}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(\n",
    "    model_path,\n",
    "    learning_rate=lr,\n",
    "    mini_batch_size=16,\n",
    "    mini_batch_chunk_size=4,  \n",
    "    max_epochs=max_epochs,\n",
    "    monitor_test=True,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"Apple was founded by Steve Jobs .\"   [− Tokens: 7  − Token-Labels: \"Apple <B-ORG> was founded by Steve <B-PER> Jobs <I-PER> .\"]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "sentence = Sentence([\"Apple\", \"was\", \"founded\", \"by\", \"Steve\", \"Jobs\", \".\"])\n",
    "for token, tag in zip(sentence.tokens, [\"B-ORG\", \"O\", \"O\", \"O\", \"B-PER\", \"I-PER\", \"O\"]):\n",
    "    token.set_label(\"ner\", tag)\n",
    "sentence\n",
    "\n",
    "# predict tags and print\n",
    "#model.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-11 01:51:27,004 loading file C:/Users/DELL/models/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "loaded_model: RelationExtractor = RelationExtractor.load(\n",
    "        \"C:/Users/DELL/models/best-model.pt\"\n",
    "    )\n",
    "loaded_model.train_on_gold_pairs_only = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"In 1969 , James Earl Ray pleaded guilty in Memphis , Tenn. , to the assassination of civil rights leader Martin Luther King Jr .\"   [− Tokens: 25  − Token-Labels: \"In 1969 , James <B-Peop> Earl <I-Peop> Ray <I-Peop> pleaded guilty in Memphis <B-Loc> , <I-Loc> Tenn. <I-Loc> , to the assassination of civil rights leader Martin <B-Peop> Luther <I-Peop> King <I-Peop> Jr <I-Peop> .\"  − Sentence-Labels: {'sentence_id': [5124 (1.0)], 'relation': [Kill from James Earl Ray (4,5,6) -> Martin Luther King Jr (21,22,23,24) (1.0)], 'entity': [Peop [James Earl Ray (4,5,6)] (1.0), Loc [Memphis , Tenn. (10,11,12)] (1.0), Peop [Martin Luther King Jr (21,22,23,24)] (1.0)], 'ner': [Peop [James Earl Ray (4,5,6)] (1.0), Loc [Memphis , Tenn. (10,11,12)] (1.0), Peop [Martin Luther King Jr (21,22,23,24)] (1.0)], 'predicted': [Live_In from James Earl Ray (4,5,6) -> Memphis , Tenn. (10,11,12) (0.698), Kill from James Earl Ray (4,5,6) -> Martin Luther King Jr (21,22,23,24) (0.994)]}]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.test[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "Sentence: \"In 1969 , James Earl Ray pleaded guilty in Memphis , Tenn. , to the assassination of civil rights leader Martin Luther King Jr .\"   [− Tokens: 25]\n"
     ]
    }
   ],
   "source": [
    "sent1 = [ str(str(i).split()[-1]) for i in corpus.test[3].tokens]\n",
    "print(len(sent1))\n",
    "sent = Sentence(sent1)\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, tag in zip(sent.tokens, [\"O\", \"O\", \"O\", \"B-Peop\", \"O\", \"I-Peop\", \"O\", \"O\",\"O\", \"B-Loc\", \"<I-Loc>\", \"<I-Loc>\",\"O\", \"O\", \"O\", \"O\",\"O\", \"O\", \"O\", \"O\",\"O\", \"<B-Peop>\", \"I-Peop\", \"I-Peop\",\"I-Peop\",\"O\"]):\n",
    "    token.set_label(\"ner\", tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"In 1969 , James Earl Ray pleaded guilty in Memphis , Tenn. , to the assassination of civil rights leader Martin Luther King Jr .\"   [− Tokens: 25  − Token-Labels: \"In 1969 , James <B-Peop> Earl Ray <I-Peop> pleaded guilty in Memphis <B-Loc> , <<I-Loc>> Tenn. <<I-Loc>> , to the assassination of civil rights leader Martin Luther <<B-Peop>> King <I-Peop> Jr <I-Peop> . <I-Peop>\"]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Live_In from James (4) -> Memphis (10) (0.8297),\n",
       " Live_In from James (4) -> Tenn. (12) (0.5347),\n",
       " Kill from James (4) -> Luther (22) (0.8651),\n",
       " Kill from Ray (6) -> James (4) (0.9795),\n",
       " Live_In from Ray (6) -> Memphis (10) (0.6571),\n",
       " Kill from Ray (6) -> Luther (22) (0.9951),\n",
       " Located_In from Memphis (10) -> Tenn. (12) (0.5527),\n",
       " Live_In from Luther (22) -> Memphis (10) (0.8212),\n",
       " Live_In from Luther (22) -> Tenn. (12) (0.5061)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.get_labels(\"relation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RelationExtractor(\n",
       "  (loss_function): CrossEntropyLoss()\n",
       "  (token_embeddings): WordEmbeddings('glove')\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (decoder): Linear(in_features=400, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to Understand the objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"Very strong south winds accompanied the storm system , with 50-to 70-mph wind gusts reported near Grande Isle and St. Albans , Vt. , blowing down a large radio tower and causing several power outages .\"   [− Tokens: 36  − Token-Labels: \"Very strong south winds accompanied the storm system , with 50-to 70-mph wind gusts reported near Grande <B-Loc> Isle <I-Loc> and St. <B-Loc> Albans <I-Loc> , Vt. <B-Loc> , blowing down a large radio tower and causing several power outages .\"  − Sentence-Labels: {'sentence_id': [1024 (1.0)], 'relation': [Located_In from Grande Isle (17,18) -> Vt. (23) (1.0), Located_In from St. Albans (20,21) -> Vt. (23) (1.0)], 'entity': [Loc [Grande Isle (17,18)] (1.0), Loc [St. Albans (20,21)] (1.0), Loc [Vt. (23)] (1.0)], 'ner': [Loc [Grande Isle (17,18)] (1.0), Loc [St. Albans (20,21)] (1.0), Loc [Vt. (23)] (1.0)]}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Located_In', 'Work_For', 'Live_In', 'OrgBased_In', 'Kill', 'O']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict.get_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"Three retinol dehydrogenases ( RDHs ) were tested for steroid converting abilities : human and murine RDH 12 and human RDH13 .\"   [− Tokens: 22  − Token-Labels: \"Three retinol <B-GENE/B-CHEMICAL> dehydrogenases <I-GENE> ( RDHs <B-GENE> ) were tested for steroid converting abilities : human <B-GENE> and <I-GENE> murine <I-GENE> RDH <I-GENE> 12 <I-GENE> and human <B-GENE> RDH13 <I-GENE> .\"  − Sentence-Labels: {'sentence_id': [2 (1.0)], 'entity': [GENE [retinol dehydrogenases (2,3)] (1.0), GENE [RDHs (5)] (1.0), GENE [human and murine RDH 12 (14,15,16,17,18)] (1.0), GENE [human RDH13 (20,21)] (1.0), CHEMICAL [retinol (2)] (1.0)], 'ner': [GENE [retinol dehydrogenases (2,3)] (1.0), GENE [RDHs (5)] (1.0), GENE [human and murine RDH 12 (14,15,16,17,18)] (1.0), GENE [human RDH13 (20,21)] (1.0)]}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"To determine whether ChREBP is a potential therapeutic target , we decreased hepatic expression of ChREBP with a specific antisense oligonucleotide ( ASO ) in male Sprague-Dawley rats fed either a high-fructose or high-fat diet .\"   [− Tokens: 36  − Token-Labels: \"To determine whether ChREBP <B-GENE> is a potential therapeutic target , we decreased hepatic expression of ChREBP <B-GENE> with a specific antisense oligonucleotide ( ASO ) in male Sprague-Dawley rats fed either a high-fructose <B-CHEMICAL> or high-fat diet .\"  − Sentence-Labels: {'sentence_id': [5 (1.0)], 'entity': [GENE [ChREBP (4)] (1.0), GENE [ChREBP (16)] (1.0), CHEMICAL [high-fructose (32)] (1.0)], 'ner': [GENE [ChREBP (4)] (1.0), GENE [ChREBP (16)] (1.0), CHEMICAL [high-fructose (32)] (1.0)]}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"W. Dale Nelson covers the White House for The Associated Press .\"   [− Tokens: 12  − Token-Labels: \"W. <B-Peop> Dale <I-Peop> Nelson <I-Peop> covers the White <B-Loc> House <I-Loc> for The <B-Org> Associated <I-Org> Press <I-Org> .\"  − Sentence-Labels: {'sentence_id': [46 (1.0)], 'relation': [Work_For from W. Dale Nelson (1,2,3) -> The Associated Press (9,10,11) (1.0)], 'entity': [Peop [W. Dale Nelson (1,2,3)] (1.0), Loc [White House (6,7)] (1.0), Org [The Associated Press (9,10,11)] (1.0)], 'ner': [Peop [W. Dale Nelson (1,2,3)] (1.0), Loc [White House (6,7)] (1.0), Org [The Associated Press (9,10,11)] (1.0)]}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-03 15:01:09,166 Reading data from C:\\Users\\DELL\\.flair\\datasets\\re_english_conll04\n",
      "2021-11-03 15:01:09,166 Train: C:\\Users\\DELL\\.flair\\datasets\\re_english_conll04\\conll04-train.conllu\n",
      "2021-11-03 15:01:09,183 Dev: C:\\Users\\DELL\\.flair\\datasets\\re_english_conll04\\conll04-dev.conllu\n",
      "2021-11-03 15:01:09,186 Test: C:\\Users\\DELL\\.flair\\datasets\\re_english_conll04\\conll04-test.conllu\n"
     ]
    }
   ],
   "source": [
    "corpus = RE_ENGLISH_CONLL04()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"Very strong south winds accompanied the storm system , with 50-to 70-mph wind gusts reported near Grande Isle and St. Albans , Vt. , blowing down a large radio tower and causing several power outages .\"   [− Tokens: 36  − Token-Labels: \"Very strong south winds accompanied the storm system , with 50-to 70-mph wind gusts reported near Grande <B-Loc> Isle <I-Loc> and St. <B-Loc> Albans <I-Loc> , Vt. <B-Loc> , blowing down a large radio tower and causing several power outages .\"  − Sentence-Labels: {'sentence_id': [1024 (1.0)], 'relation': [Located_In from Grande Isle (17,18) -> Vt. (23) (1.0), Located_In from St. Albans (20,21) -> Vt. (23) (1.0)], 'entity': [Loc [Grande Isle (17,18)] (1.0), Loc [St. Albans (20,21)] (1.0), Loc [Vt. (23)] (1.0)]}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "673a99767848cb7d35ee205e5e64298b812442fab0c68f5f28d800550018a90d"
  },
  "kernelspec": {
   "display_name": "gdm36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
